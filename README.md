ğŸ§  Perplexity Clone â€“ AI-Powered Search Assistant

This project is a full-stack clone of Perplexity.ai, a conversational search engine that combines real-time web search with AI to provide accurate, source-backed answers.

ğŸš€ Features
â€¢ Real-time web search using SerpAPI
â€¢ Intelligent text extraction from web pages using boilerpy3
â€¢ Semantic search using FAISS vector store
â€¢ Real-time answer streaming with OpenAI's GPT-4
â€¢ Source citations for all answers
â€¢ Modern, responsive UI with Next.js
â€¢ Efficient embedding caching for faster responses

ğŸ”§ Tech Stack
â€¢ Frontend:
  - Next.js 15 with TypeScript
  - Tailwind CSS for styling
  - Real-time streaming with Server-Sent Events

â€¢ Backend:
  - FastAPI for high-performance API
  - OpenAI GPT-4 for answer generation
  - FAISS for semantic search
  - SerpAPI for web search
  - boilerpy3 for web scraping
  - Embedding caching for performance

ğŸ¯ Key Features
â€¢ Real-time answer streaming for better UX
â€¢ Semantic search to find most relevant content
â€¢ Efficient caching of embeddings
â€¢ Source-backed answers with clickable citations
â€¢ Modern, responsive UI with dark mode support

ğŸš€ Getting Started

1. Clone the repository
2. Set up environment variables:
   ```
   OPENAI_API_KEY=your_openai_key
   SERPAPI_KEY=your_serpapi_key
   ```

3. Install backend dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Install frontend dependencies:
   ```bash
   cd perplexity-ui
   npm install
   ```

5. Run the development servers:
   ```bash
   # Terminal 1 - Backend
   uvicorn backend.main:app --reload

   # Terminal 2 - Frontend
   cd perplexity-ui
   npm run dev
   ```

6. Open http://localhost:3000 in your browser

ğŸ” How It Works
1. User asks a question
2. System searches the web using SerpAPI
3. Relevant pages are scraped and processed
4. Content is chunked and embedded
5. Semantic search finds most relevant chunks
6. GPT-4 generates a streaming answer
7. Sources are provided for verification

